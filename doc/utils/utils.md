# `utils.utils(utils/utils.py)`
#### `def ap_per_class(tp, conf, pred_cls, target_cls)`
- 功能：计算出每个类别预测的`precise, recall, AP, f1`值
- 函数参数
  - `tp:` `NMS`过滤后所有预测框是否为准确预测，`tp[pred_i] == 1`表示预测框`pred_i`为正确检测`TP`，否则`tp[pred_i] == 0`表示预测框`pred_i`为正确检测`FP`(`tensor([NMS过滤后的预测框总数])`)
  - `conf:` `NMS`过滤后所有预测框的置信度(`tensor([NMS过滤后的预测框总数])`)
  - `pred_cls:` `NMS`过滤后所有预测框的预测类别(`tensor([NMS过滤后的预测框总数])`)
  - `target_cls:` 所有真实目标框的类别(`tensor([真实目标框总数])`)
- 函数返回
  - `p:` 不同类别预测的精确值(`list(存在的类别数量 * double)`)
  - `r:` 不同类别预测的召回值(`list(存在的类别数量 * double)`)
  - `ap:` 不同类别预测的`AP`值(`list(存在的类别数量 * double)`)
  - `f1:` 不同类别预测的`f1`值(`list(存在的类别数量 * double)`)
  - `ap_class:` 真实目标框中存在的类别id(`list(存在的类别数量 * int)`)
- 代码细节
  - `tp, conf, pred_cls`根据`conf`从大到小排序
  - `unique_class: `真实目标框中存在的类别(`list(存在类别数量 * int)`)
  - `c:` 遍历不同类别的标签
    - `n_gt:` 类别为`c`的真实目标框个数(`int`)
    - `n_p:` 类别为`c`的预测目标框个数(`int`)
    - `fpc:` `fpc[i]`为第`0-i`个预测目标框中的错误预测数`FP`
    - `tpc:` `tpc[i]`为第`0-i`个预测目标框中的正确预测数`TP`
    - `recall_curve:` `recall_curve[i]`为第`0-i`个预测目标框的召回值
    - `r:` 类别`c`的召回值
    - `precision_curve:` `precision_curve[i]`为第`0-i`个预测目标框的精确值
    - `p:` 类别`c`的精确值
    - `ap:` [compute_ap(recall_curve, precision_curve)][compute_ap]计算出每个类别的`AP`值
  - `f1:` 计算出不同类别的f1值

#### `def compute_ap(recall, precision)`
- 功能：通过`recall`和`precision`数组计算出`AP`值
- 函数参数
  - `recall:` `recall[i]`为第`0-i`个预测目标框的召回值，目标框的置信度从大到小排序(`numpy([预测目标框数目])`)
  - `precision:` `precision[i]`为第`0-i`个预测目标框的精确值，目标框的置信度从大到小排序(`numpy([预测目标框数目])`)
- 函数返回
  - `AP:` `recall-precision`曲线的面积(`int`)
- 代码细节
  - 采用积分的方法计算出`recall-precision`曲线的面积

#### `def get_batch_statistics(outputs, targets, iou_threshold)`
- 功能：参考[COCO mAP]的计算方法，计算`tp, fp, 预测置信度和预测类别id`
- 函数参数
  - `outputs:` `batch`个图片经过`NMS`过滤后的预测框(`list(batch_size * tensor([m, 7(x1, y1, x2, y2, c, class_conf, class_pred)]))`)
  - `targets:` `batch`个图片的真实目标框(`二维tensor数组，tensor([sumBatch(目标框数), 6])。targets[bbox_i] = tensor([batch_i, 目标类别id, x1, y1, x2, y2])，且值在[0, img_size]的范围内`)
  - `iou_threshold:` 如果预测目标框与真实目标框之间的`IOU > iou_threshold`则认为预测匹配了相关真实目标框(`int`)
- 函数返回
  - `batch_metrics:` 类型为`list(batch_size * list[true_positives, pred_scores, pred_labels])`。
    - `true_positives:` 记录了预测框是否正确。如果`true_positives[pred_i] == 1`，则表明预测框`pred_id`正确检测了目标，否则为错误预测(`list(m * int)`)
    - `pred_score:` 记录了预测框的置信度，该向量不一定是从大到小有序的，因为是按pred_score*label_score从大到小排序的(`tensor([m])`)
    - `pred_labels:` 记录了预测框检测到的类别(`tensor([m])`)
- 代码细节
  - 遍历`sample_i = range(len(output))`
    - `annotations:` 获得第`batch_i`张图片的真实检测框(`二维tensor数组，tensor([目标框数, 5])。targets[bbox_i] = tensor([目标类别id, x1, y1, x2, y2])，且值在[0, img_size]的范围内`)
    - `target_labels:` 真是目标框的类别(`tensor([目标框数])`)
    - `target_boxes:` 真是目标框的信息(`二维tensor数组，tensor([目标框数, 5])。targets[bbox_i] = tensor([目标类别id, x1, y1, x2, y2])，且值在[0, img_size]的范围内`)
    - `detected_boxes:` 保存已被匹配的真实目标框的`index`
    - 遍历`pred_i, (pred_box, pred_label) = enumerate(zip(pred_boxes, pred_labels)):`
      - 如果预测类别`pred_label not in target_labels`，则`continue`
      - `iou:` 预测框`pred_box`与所有真实预测框之间的最大IOU值，**不约束预测框与真实框同类别mAP=0.515,约束同类别mAP=0.503**
      - `box_index:` 预测框`pred_box`与所有真实预测框`target[box_index]`之间的IOU值最大
      - 如果满足`iou > iou_threshold and box_index not in detected_box`，则：
        - `true_positives[pred_i] = 1`
        - `detected_box += box_index`
    - `batch_metrics.append([true_positives, pred_scores, pred_labels])`

#### `def bbox_iou(box1, box2, x1y1x2y2=True)`
- 功能：计算`box1`与`box2`之间的`IOU`
- 函数参数
  - `box1:` 目标框1信息(`box1.shape = torch.Size([1, 4])`)
  - `box2:` 目标框2信息(`box2.shape = torch.Size([n, 4])`)
  - `x1y1x2y2:` 目标框的信息是否是`(x1, y1, x2, y2)`的形式，如果不是，会转化为相应形式
- 函数返回
  - `iou:` 目标框1与目标框2之间的IOU值(`iou.shape = torch.Size([n, 1])`)
- 代码细节
  - `b1_x1, b1_y1, b1_x2, b1_y2:` 目标框1的左上角点和右下角点信息。
  - `b2_x1, b2_y1, b2_x2, b2_y2:` 目标框2的左上角点和右下角点信息。
  - `inter_area:` 目标框1与目标框2之间的交叉面积(`inter_area.shape = torch.Size([n, 1])`)
  - `b1_area:` 目标框1的面积(`b1_area.shape = torch.Size([n, 1])`)
  - `b2_area:` 目标框2的面积(`b2_area.shape = torch.Size([n, 1])`)
  - `iou:` 目标框1与目标框2之间的IOU值(`iou.shape = torch.Size([n, 1])`)

#### `def non_max_suppression(prediction, conf_thres=0.5, nms_thres=0.4)`
- 功能：非极大值抑制，过滤掉部分预测框。
- 函数参数
  - `prediction:` 模型的预测框结果(`三维tensor, torch.Size([8, 10647(13*13*3 + 26*26*3 + 52*52*3), 85(5 + 80)])`)
  - `conf_thres:` `预测框置信度 < opt.conf_thres`则直接筛除(`0.001`)
  - `nms_thres:` `NMS`时，`iou > opt.nms_thres`的边界框会被抑制(`0.5`)
- 函数返回
  - `output:` 非极大值抑制筛选后得到，置信度从大到小的预测框(`list(batch_size * tensor([m, 7(x1, y1, x2, y2, c, class_conf, class_pred)]))`)
- 代码细节
  - 将预测框的`(center_x, center_y, width, height)`信息转化成`(x1, y1, x2, y2)`信息
  - `image_pred:` 遍历`batch`的预测框`prediction`，得到每个图的预测框`image_pred`(`image_pred.shape = torch.Size([10647, 85])`)
    - `image_pred:` 过滤掉置信度小于conf_thres的预测框(`image_pred.shape = torch.Size([n(n<10647), 85])`)
    - `score:` 置信度*最大类别预测值得到最终预测框的置信度(`score.shape = torch.Size([n, 1])`)
    - `image_pred:` 根据`score`从大到小排序。
    - `class_confs:` 类别预测值中最大的值(`class_confs.shape = torch.Size([n, 1])`)
    - `class_preds:` 类别预测值中最大值的下标(`class_preds.shape = torch.Size([n, 1])`)
    - `detections:` 拼接预测框，类别置信度，类别id(`class_preds.shape = torch.Size([n, 7(x1, y1, x2, y2, c, class_conf, class_pred)])`)
    - `keep_boxes:` 一张图片经过`NMS`后的预测框(`keep_boxes.shape = torch.Size([m(m<n), 7])`)
    - 持续循环直到`detections`为空：
      - `detections[0]`加入到`keep_boxes`中
      - `large_overlap:` `detection`中与`detections[0]`的`iou`值是否大于`nms_thres`
      - `label_match:` `detection`的类别是否与`detections[0]`相同
      - `detections:` 剔除掉`detections`中与`detections[0]`类别相同且`iou > nms_thres`的`detection`
    - `output[image_i] = keep_boxes:` 保存不同图片的最终预测框
    
#### def build_targets(pred_boxes, pred_cls, target, anchors, ignore_thres)
- 功能：。
- 函数参数
  - `pred_boxes:` 预测目标框在[0, grid_size]坐标系下的(x, y, w, h)
  - `pred_cls:` 预测目标框的类别
  - `target:` 真实目标框在[0, 1]坐标系下的(x, y, w, h)`(6维变量batch_i, label, x, y, w, h)`
  - `anchors:` 特征图中锚的尺寸大小
  - `ignore_thres:` 如果除最大iou以外的锚与真实目标框的`wh_iou > ignore_thres`, 则特征图点无法判断是否存在目标，不计算损失函数。
- 函数返回
  - `iou_scores:` 预测特征图与真实目标框之间的`iou``(torch.shape = [batch_n, anchors_n, grid_size, grid_size, target_n]))`
  - `class_mask:` 预测特征图与真实目标框类别是否匹配`(torch.shape = [batch_n, anchors_n, grid_size, grid_size, target_n]))`
  - `obj_mask:` 特征图存在目标的二值图`(torch.shape = [batch_n, anchors_n, grid_size, grid_size])`
  - `noobj_mask:` 特征图不存在目标的二值图`(torch.shape = [batch_n, anchors_n, grid_size, grid_size])`
  - `tx:` 应该预测存在目标的特征图应该输出的左上角横坐标`(torch.shape = [batch_n, anchors_n, grid_size, grid_size], [0, 1]坐标系)`
  - `ty:` 应该预测存在目标的特征图应该输出的左上角纵坐标`(torch.shape = [batch_n, anchors_n, grid_size, grid_size], [0, 1]坐标系)`
  - `tw:` 应该预测存在目标的特征图应该输出的宽`(torch.shape = [batch_n, anchors_n, grid_size, grid_size])`
  - `th:` 应该预测存在目标的特征图应该输出的高`(torch.shape = [batch_n, anchors_n, grid_size, grid_size])`
  - `tcls:` 应该输出的类别`(torch.shape = [batch_n, anchors_n, grid_size, grid_size]))`
  - `tconf:` 特征图存在目标的二值图`(torch.shape = [batch_n, anchors_n, grid_size, grid_size])`
- 函数细节
  - `target_boxes = target[:, 2:6] * nG:` 真实目标框在[0, grid_size]坐标系下的(x, y, w, h)`(torch.shape = [target_n, 4])`
  - `gxy = target_boxes[:, :2]:` 真实目标框在[0, grid_size]坐标系下的左上角坐标`(torch.shape = [target_n, 2])`
  - `gwh = target_boxes[:, 2:]:` 真实目标框在[0, grid_size]坐标系下的宽高`(torch.shape = [target_n, 2])`
  - `ious:` 不同尺寸锚(宽高)与预测框(宽高)之间的`iou``(torch.shape = [anchor_num, pred_num])`
  - `best_ious:` 预测框(宽高)与锚(宽高)之间的最大iou值`(torch.shape = [pred_num])`
  - `best_n:` 预测框(宽高)与锚(宽高)之间的最大iou的锚id`(torch.shape = [pred_num])`
  - `b:` 真实目标框位于`batch`中的`id``(torch.shape = [target_num])`
  - `target_labels:` 真实目标框的类别`id``(torch.shape = [target_num])`
  - `gx, gi:` 真实目标框在[0, grid_size]坐标系下的左上角横坐标`(torch.shape = [target_num])`
  - `gy, gj:` 真实目标框在[0, grid_size]坐标系下的左上角横坐标`(torch.shape = [target_num])`
  - `gw:` 真实目标框在[0, grid_size]坐标系下的宽`(torch.shape = [target_num])`
  - `gh:` 真实目标框在[0, grid_size]坐标系下的高`(torch.shape = [target_num])`
  - `obj_mask[b, best_n, gj, gi] = 1:` 特征图存在目标的二值图`(torch.shape = [batch_n, anchors_n, grid_size, grid_size])`
  - `noobj_mask[b, best_n, gj, gi] = 1:` 特征图不存在目标的二值图`(torch.shape = [batch_n, anchors_n, grid_size, grid_size])`
  - `noobj_mask[b[i], anchor_ious > ignore_thres, gj[i], gi[i]] = 0:` 如果除最大iou以外的锚与真实目标框的`wh_iou > ignore_thres`, 则特征图点无法判断是否存在目标，不计算损失函数。
  - `tx[b, best_n, gj, gi] = gx - gx.floor():` 特征图应该输出的左上角横坐标偏置`([0, 1]坐标系)`
  - `ty[b, best_n, gj, gi] = gy - gy.floor():` 特征图应该输出的左上角纵坐标偏置`([0, 1]坐标系)`
  - `tw[b, best_n, gj, gi] = log(gw / anchors[best_n][0]):` 特征图应该输出的宽偏置
  - `th[b, best_n, gj, gi] = log(gh / anchors[best_n][0]):` 特征图应该输出的高偏置
  - `tcls[b, best_n, gj, gi, target_labels] = 1:` 特征图应该输出的类别`(torch.shape = [batch_n, anchors_n, grid_size, grid_size]))`
  - `class_mask[b, best_n, gj, gi]:` 预测特征图与真实目标框类别是否匹配`(torch.shape = [batch_n, anchors_n, grid_size, grid_size, target_n]))`
  - `iou_scores[b, best_n, gj, gi]:` 预测特征图与真实目标框之间的`iou``(torch.shape = [batch_n, anchors_n, grid_size, grid_size, target_n]))`
  - `tconf = obj_mask.float()`

[COCO mAP]:<https://github.com/LbyG/MOT-Paper-Notes/blob/master/evaluate-metric.md#map%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B>
[compute_ap]:<utils.md#def-compute_aprecall-precision>
